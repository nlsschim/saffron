{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d8d5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "from skimage.measure import block_reduce, label, regionprops\n",
    "from skimage.color import label2rgb\n",
    "import tifffile as tiff\n",
    "import matplotlib.pyplot as plt\n",
    "from nd2 import ND2File\n",
    "from pathlib import Path\n",
    "from skimage.morphology import remove_small_objects\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage import filters\n",
    "from scipy import ndimage\n",
    "\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib.patches import Circle\n",
    "\n",
    "from sklearn.metrics.pairwise import paired_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e759b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "\n",
    "\n",
    "__all__ = [\n",
    "    \"apply_gaussian_filter\",\n",
    "    \"remove_baseline\",\n",
    "    \"binarize\",\n",
    "]\n",
    "\n",
    "\n",
    "def apply_gaussian_filter(\n",
    "    img: np.ndarray, sigma: int, radius: Optional[int] = None, debug: bool = False\n",
    ") -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"applies a 2D highpass filter to remove baseline drift and detect edges, or to blur image\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    img: image\n",
    "\n",
    "    sigma: sigma for gaussian kernel\n",
    "\n",
    "    radius: Optional radius for gaussian kernel\n",
    "\n",
    "    debug: whether to display figures intended for development\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    lowpass filtered image, highpass filtered image\n",
    "    \"\"\"\n",
    "    # normalize and discretize pixel intensities\n",
    "    img = img.copy().astype(np.float64)\n",
    "    img -= np.min(img.flatten())\n",
    "    img *= 256 / np.max(img.flatten())\n",
    "    img = np.round(img, 0).astype(np.int64)\n",
    "\n",
    "    # filter image\n",
    "    gauss_lowpass = ndimage.gaussian_filter(img, sigma, radius=radius)\n",
    "    gauss_highpass = np.array(img, dtype=np.int64) - np.array(\n",
    "        gauss_lowpass, dtype=np.int64\n",
    "    )\n",
    "    min_highpass = np.min(np.min(gauss_highpass))\n",
    "    if min_highpass < 0:\n",
    "        gauss_highpass -= min_highpass\n",
    "\n",
    "    if debug:\n",
    "        # gauss_highpass = np.max(np.max(gauss_highpass)) - gauss_highpass\n",
    "        print(f\"original range: ({np.min(np.min(img))}, {np.max(np.max(img))})\")\n",
    "        print(\n",
    "            f\"lowpass range:  ({np.min(np.min(gauss_lowpass))}, {np.max(np.max(gauss_lowpass))})\"\n",
    "        )\n",
    "        print(\n",
    "            f\"highpass range: ({np.min(np.min(gauss_highpass))}, {np.max(np.max(gauss_highpass))})\"\n",
    "        )\n",
    "\n",
    "        fig0 = plt.figure()\n",
    "        ax0 = plt.gca()\n",
    "        fig0.suptitle(\"Original\")\n",
    "        ax0.imshow(img, cmap=\"gray\")\n",
    "\n",
    "        fig1 = plt.figure()\n",
    "        ax1 = plt.gca()\n",
    "        fig1.suptitle(\"Lowpass\")\n",
    "        ax1.imshow(gauss_lowpass, cmap=\"gray\")\n",
    "\n",
    "        fig2 = plt.figure()\n",
    "        ax2 = plt.gca()\n",
    "        fig2.suptitle(\"Highpass\")\n",
    "        ax2.imshow(gauss_highpass, cmap=\"gray\")\n",
    "\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    return (gauss_lowpass, gauss_highpass)\n",
    "\n",
    "\n",
    "def remove_baseline(img: np.ndarray, factor: int | float = 4) -> np.ndarray:\n",
    "    \"\"\"uses a highpass filter to remove baseline\"\"\"\n",
    "    dim = min([*np.shape(img)])\n",
    "    baseline, no_baseline = apply_gaussian_filter(img, sigma=int(np.ceil(dim / factor)))\n",
    "\n",
    "    return no_baseline\n",
    "\n",
    "\n",
    "def remove_baseline_DEBUGGING(img: np.ndarray, factor: int | float = 4) -> np.ndarray:\n",
    "    \"\"\"uses a highpass filter to remove baseline\"\"\"\n",
    "    dim = min([*np.shape(img)])\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    factors = 5 * np.logspace(0, 2, num=5, endpoint=True, base=10)\n",
    "    for f in [*factors, 128]:\n",
    "        baseline, no_baseline = apply_gaussian_filter(img, sigma=int(f), debug=False)\n",
    "        fig, ax = plt.subplots(1, 3)\n",
    "        fig.suptitle(f\"{f}\\n{np.min(no_baseline):.3f}, {np.max(no_baseline):.3f}\")\n",
    "        ax[0].imshow(img)\n",
    "        ax[1].imshow(baseline)\n",
    "        ax[2].imshow(no_baseline)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    import sys\n",
    "\n",
    "    sys.exit()\n",
    "\n",
    "    return no_baseline\n",
    "\n",
    "\n",
    "def binarize(\n",
    "    highpass_img: np.ndarray,\n",
    "    opt_thresh: bool = False,\n",
    "    thresh: int | float = 0.5,\n",
    "    show_hist: bool = False,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"masks image\n",
    "\n",
    "    Parameters:\n",
    "        img: should be highpass-filtered to remove baseline and enhance edges\n",
    "        opt_thresh: whether the program should decide the optimal pixel intensity threshold\n",
    "        thresh: float between 0 and 1. Sets threshold for binarizing image\n",
    "        show_hist: for development only. shows histogram of intensities\n",
    "\n",
    "    Returns:\n",
    "        binarized image of same dimensions\n",
    "\n",
    "    Raises:\n",
    "        ValueError if thresh is out of range\n",
    "    \"\"\"\n",
    "    if 0 > thresh or thresh > 1:\n",
    "        raise ValueError(f\"thresh must be between 0 and 1. Received value of {thresh}\")\n",
    "\n",
    "    max_val = int(np.max(np.max(highpass_img)))\n",
    "    min_val = int(np.min(np.min(highpass_img)))\n",
    "    thresh_val = thresh * max_val + (1 - thresh) * min_val\n",
    "\n",
    "    if opt_thresh:\n",
    "        try:\n",
    "            hist, bins = np.histogram(\n",
    "                highpass_img.flatten(),\n",
    "                bins=round(max_val - min_val + 1),\n",
    "            )\n",
    "            peak = np.argmax(hist)\n",
    "            hist_high = hist[peak:]\n",
    "            bins_high = bins[peak:-1]\n",
    "            thresh_val = np.min(bins_high[hist_high < 0.5 * hist[peak]])\n",
    "            # thresh_val = bins_high[np.argmin(np.diff(hist_high))]\n",
    "        except:\n",
    "            warnings.warn(\n",
    "                \"Unable to use optimal threshold. Using default threshold.\",\n",
    "                category=UserWarning,\n",
    "            )\n",
    "\n",
    "    if show_hist:\n",
    "        plt.figure()\n",
    "        plt.title(\"Pixel Intensities\")\n",
    "        plt.hist(highpass_img.copy().flatten(), bins=100)\n",
    "        plt.axvline(thresh_val, color=\"r\")\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    bin_img = np.zeros_like(highpass_img, dtype=np.int64)\n",
    "    bin_img[highpass_img > thresh_val] = 1\n",
    "\n",
    "    return bin_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f0696e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# from reader import nd2_img_reader, get_stain\n",
    "# from .filters import (\n",
    "#     apply_gaussian_filter,\n",
    "#     remove_baseline,\n",
    "#     binarize,\n",
    "#     remove_baseline_DEBUGGING,\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "def mask_img(img: np.ndarray, **kwargs) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Masks image\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    img: np.ndarray of image (N x M)\n",
    "\n",
    "    bin_thresh: intensity threshold to binarize image (range: 0-1, default = 0.1)\n",
    "\n",
    "    filter_coeff: coefficient to filter image. Smaller numbers remove baseline more effectively (default = 4)\n",
    "\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    masked image containing filtered values within cell bounds\n",
    "\n",
    "    mask used for this calculation\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        \"bin_thresh\": 0.1,\n",
    "        \"filter_coeff\": 4,\n",
    "        \"opt_thresh\": False,\n",
    "    }\n",
    "    params.update(kwargs)\n",
    "\n",
    "    filtered = remove_baseline(img, params[\"filter_coeff\"])\n",
    "    mask = binarize(\n",
    "        filtered, opt_thresh=params[\"opt_thresh\"], thresh=params[\"bin_thresh\"]\n",
    "    )\n",
    "\n",
    "    masked_img = mask * filtered\n",
    "\n",
    "    values = masked_img.copy().flatten()\n",
    "    nonzero = values[values > 0]\n",
    "    shift = mask * float(np.min(nonzero)) if (len(nonzero) > 0) else 0\n",
    "    masked_img_shifted = masked_img - shift\n",
    "\n",
    "    return (masked_img_shifted, mask)\n",
    "\n",
    "\n",
    "def highlight_mask_edges(mask: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"uses gaussian filter to highlight edges\"\"\"\n",
    "    centers, edges = apply_gaussian_filter(mask, sigma=1, radius=2)\n",
    "    edges_bin = np.zeros_like(edges, dtype=np.int64)\n",
    "    edges_bin[edges > 0.5] = 1\n",
    "\n",
    "    return edges_bin\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_image(\n",
    "    img: np.ndarray, filter_coeff: int, bin_thresh: float = 0.1, opt_thresh: bool = False\n",
    ") -> tuple[np.ndarray, ...]:\n",
    "    \"\"\"Preprocesses images\n",
    "\n",
    "    Arguments:\n",
    "        img: DAPI-stained microscopy image\n",
    "\n",
    "    Results:\n",
    "        preprocessed image,\n",
    "        mask,\n",
    "        mask_edges,\n",
    "    \"\"\"\n",
    "    # normalize\n",
    "    norm_img = img.copy().astype(np.float64)\n",
    "    norm_img -= np.min(norm_img.flatten())\n",
    "    norm_img /= np.max(norm_img.flatten())\n",
    "\n",
    "    # develop masks\n",
    "    masked_img, mask = mask_img(\n",
    "        norm_img, bin_thresh=bin_thresh, filter_coeff=filter_coeff, opt_thresh=opt_thresh\n",
    "    )\n",
    "    #mask_edges = highlight_mask_edges(mask)\n",
    "\n",
    "    return (masked_img, mask)#, mask_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee04e558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_image_paths_in_subfolders(root_path):\n",
    "    \"\"\"\n",
    "    Recursively finds all .tif/.tiff files in `root_path` and returns a list of full file paths.\n",
    "    \"\"\"\n",
    "    image_files = []\n",
    "    for current_dir, subdirs, files in os.walk(root_path):\n",
    "        for file in files:\n",
    "            if file.lower().endswith('.tif') or file.lower().endswith('.tiff'):\n",
    "                image_files.append(os.path.join(current_dir, file))\n",
    "    return image_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42608251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_batch_channel_stats(all_image_paths, channels=4, lower_percentile=0.05, upper_percentile=99.95):\n",
    "    \"\"\"\n",
    "    Collect pixel values across all images (in raw space),\n",
    "    compute global min/max (percentiles) for each channel.\n",
    "    Returns min_vals[ch], max_vals[ch].\n",
    "    \"\"\"\n",
    "    all_channel_data = [[] for _ in range(channels)]\n",
    "\n",
    "    for path in all_image_paths:\n",
    "        im = tiff.imread(path).astype('float32')\n",
    "        # Move channel axis -> shape: (H, W, channels)\n",
    "        im = np.moveaxis(im, 0, -1)\n",
    "\n",
    "        for ch_idx in range(channels):\n",
    "            all_channel_data[ch_idx].extend(im[:, :, ch_idx].ravel())\n",
    "\n",
    "    min_vals = []\n",
    "    max_vals = []\n",
    "    for ch_idx in range(channels):\n",
    "        ch_data = np.array(all_channel_data[ch_idx])\n",
    "        lower_val = np.percentile(ch_data, lower_percentile)\n",
    "        upper_val = np.percentile(ch_data, upper_percentile)\n",
    "        min_vals.append(lower_val)\n",
    "        max_vals.append(upper_val)\n",
    "\n",
    "    return min_vals, max_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7ab593",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_normalise_image(image_path, min_vals, max_vals):\n",
    "    \"\"\"\n",
    "    Loads image from path, downsamples by 2, and uses global (min_vals, max_vals)\n",
    "    to normalise each channel to [0, 1].\n",
    "    \"\"\"\n",
    "    # Load raw\n",
    "    image = tiff.imread(image_path).astype('float32')\n",
    "    image = np.moveaxis(image, 0, -1)  # shape: (H, W, 4)\n",
    "\n",
    "    # Downsample\n",
    "    image = block_reduce(image, block_size=(2, 2, 1))\n",
    "\n",
    "    # Normalise each channel to [0,1] using global min/max\n",
    "    for ch_idx in range(len(min_vals)):\n",
    "        image[:, :, ch_idx] = np.clip(image[:, :, ch_idx], min_vals[ch_idx], max_vals[ch_idx])\n",
    "        denom = max_vals[ch_idx] - min_vals[ch_idx]\n",
    "        if denom > 0:\n",
    "            image[:, :, ch_idx] = (image[:, :, ch_idx] - min_vals[ch_idx]) / denom\n",
    "        else:\n",
    "            raise ValueError(f\"Error: min and max are the same for channel {ch_idx}\")\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad580a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_normalised_mito_and_sc_pixels(all_image_paths, min_vals, max_vals,\n",
    "                                         mito_channel_idx=2, sc_channel_idx=3):\n",
    "    \"\"\"\n",
    "    1) Loads each image, normalises it using the global min_vals/max_vals.\n",
    "    2) Extracts the (normalised) pixels from the mitochondria channel and 2SC channel.\n",
    "    3) Returns two big lists: all_mito_pixels_norm, all_sc_pixels_norm.\n",
    "    \"\"\"\n",
    "    all_mito_pixels_norm = []\n",
    "    all_sc_pixels_norm = []\n",
    "\n",
    "    for path in all_image_paths:\n",
    "        # Load + normalise\n",
    "        norm_image = load_and_normalise_image(path, min_vals, max_vals)\n",
    "        # Extract channels\n",
    "        mito_pixels = norm_image[:, :, mito_channel_idx].ravel()\n",
    "        sc_pixels = norm_image[:, :, sc_channel_idx].ravel()\n",
    "        all_mito_pixels_norm.extend(mito_pixels)\n",
    "        all_sc_pixels_norm.extend(sc_pixels)\n",
    "    \n",
    "    return all_mito_pixels_norm, all_sc_pixels_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60a57cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_global_thresholds_in_normalised_space(mito_pixels_norm,\n",
    "                                                  mito_percentile=95):\n",
    "    \"\"\"\n",
    "    Given two lists of normalised intensities, one for mitochondria channel and\n",
    "    one for 2SC channel, compute global threshold (e.g. 90th percentile) in normalised space.\n",
    "    \"\"\"\n",
    "    mito_pixels_norm = np.array(mito_pixels_norm)\n",
    "\n",
    "    global_mito_threshold = np.percentile(mito_pixels_norm, mito_percentile)\n",
    "\n",
    "    return global_mito_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d713a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_segmentation_with_mito_in_microglia(image, cytoplasm_mask, nucleus_mask, mito_mask, sc_mask):\n",
    "    grayscale_background = np.mean(image[:, :, :3], axis=2)\n",
    "    overlay = np.stack([grayscale_background]*3, axis=-1).astype(np.uint8)\n",
    "    \n",
    "    cytoplasm_color = [0, 255, 0]  # Green\n",
    "    nucleus_color = [255, 0, 255]  # Magenta\n",
    "    mito_color = [0, 0, 255]       # Blue\n",
    "    sc_color = [255, 0, 0]         # Red\n",
    "\n",
    "    mito_mask_cyto = np.logical_and(mito_mask, cytoplasm_mask)\n",
    "    sc_mask_cyto = np.logical_and(sc_mask, cytoplasm_mask)\n",
    "    \n",
    "    overlay[cytoplasm_mask > 0] = cytoplasm_color\n",
    "    overlay[nucleus_mask > 0] = nucleus_color\n",
    "    overlay[mito_mask_cyto > 0] = mito_color\n",
    "    overlay[sc_mask_cyto > 0] = sc_color\n",
    "    \n",
    "    return overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ddcba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nd2_to_tif(path, file_name):\n",
    "    nd2_path = Path(path) / file_name\n",
    "    tif_path = nd2_path.with_suffix(\".tif\")\n",
    "\n",
    "    with ND2File(nd2_path) as nd2_file:\n",
    "        nd2_data = nd2_file.asarray()\n",
    "        tiff.imwrite(tif_path, nd2_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3941f272",
   "metadata": {},
   "source": [
    "### Start code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc365f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_prop = pd.read_csv(\"/Users/nelsschimek/Downloads/All_Properties.csv\")\n",
    "pyknotic_df = all_prop[all_prop[\"classified_pyknotic\"] == True]\n",
    "non_pyknotic_df = all_prop[all_prop[\"classified_pyknotic\"] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "ebbe1041",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = Path('/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/ORST/cd11b')\n",
    "\n",
    "# Get all .nd2 files\n",
    "nd2_files = list(directory.glob(\"*.nd2\"))\n",
    "\n",
    "# If you want full paths as strings:\n",
    "nd2_file_paths = [str(f) for f in nd2_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "097e07e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in nd2_files:\n",
    "\n",
    "    nd2_to_tif(directory, file)\n",
    "\n",
    "# Get all .nd2 files\n",
    "tif_files = list(directory.glob(\"*.tif\"))\n",
    "\n",
    "# If you want full paths as strings:\n",
    "tif_file_paths = [str(f) for f in tif_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "330dd66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "microglia_masks = Path(\"/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/ORST/cd11b/li_thresh\")\n",
    "\n",
    "microg_npys = list(microglia_masks.glob(\"*li_thresh.npy\"))\n",
    "microglia_mask_filepaths = [str(f) for f in microg_npys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "9f0d0702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'060225_P10F_4DIV_OR10_G11_ORST_F24h_CD11B_MT_DAPI_Slice_F_40x_ctx_3.tif'"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "microglia_mask_filepaths[0].split(\"/\")[-1].replace(\"_li_thresh.npy\", \".tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "5be27d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "images = [tiff.imread(f) for f in tif_file_paths]\n",
    "print(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "6044b613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/051925_P10F_4DIV_OR9_cROT_2hROTnoOGD_F24h_DAPI_CD11B_Blank_MT_Slice_B_40x_ctx_1.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/051925_P10F_4DIV_OR9_cROT_2hROTnoOGD_F24h_DAPI_CD11B_Blank_MT_Slice_B_40x_ctx_2.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/051925_P10F_4DIV_OR9_cROT_2hROTnoOGD_F24h_DAPI_CD11B_Blank_MT_Slice_B_40x_ctx_3.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/051925_P10F_4DIV_OR9_cROT_2hROTnoOGD_F24h_DAPI_CD11B_Blank_MT_Slice_B_40x_ctx_4.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/051925_P10F_4DIV_OR9_cROT_2hROTnoOGD_F24h_DAPI_CD11B_Blank_MT_Slice_B_40x_ctx_5.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/051925_P10F_4DIV_OR9_cROT_2hROTnoOGD_F24h_DAPI_CD11B_Blank_MT_Slice_B_40x_md_1.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/051925_P10F_4DIV_OR9_cROT_2hROTnoOGD_F24h_DAPI_CD11B_Blank_MT_Slice_B_40x_md_2.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/051925_P10F_4DIV_OR9_cROT_2hROTnoOGD_F24h_DAPI_CD11B_Blank_MT_Slice_B_40x_md_3.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/051925_P10F_4DIV_OR9_cROT_2hROTnoOGD_F24h_DAPI_CD11B_Blank_MT_Slice_B_40x_md_4.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/051925_P10F_4DIV_OR9_cROT_2hROTnoOGD_F24h_DAPI_CD11B_Blank_MT_Slice_B_40x_md_5.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/051925_P10F_4DIV_OR9_cROT_2hROTnoOGD_F24h_DAPI_CD11B_Blank_MT_Slice_B_40x_md_6.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/051925_P10F_4DIV_OR9_cROT_2hROTnoOGD_F24h_DAPI_CD11b_Blank_MT_Slice_A_40xctx_1.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/051925_P10F_4DIV_OR9_cROT_2hROTnoOGD_F24h_DAPI_CD11b_Blank_MT_Slice_A_40xctx_2.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/051925_P10F_4DIV_OR9_cROT_2hROTnoOGD_F24h_DAPI_CD11b_Blank_MT_Slice_A_40xctx_3.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/051925_P10F_4DIV_OR9_cROT_2hROTnoOGD_F24h_DAPI_CD11b_Blank_MT_Slice_A_40xctx_4.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/051925_P10F_4DIV_OR9_cROT_2hROTnoOGD_F24h_DAPI_CD11b_Blank_MT_Slice_A_40xctx_5.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/051925_P10F_4DIV_OR9_cROT_2hROTnoOGD_F24h_DAPI_CD11b_Blank_MT_Slice_A_40xmd_1.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/051925_P10F_4DIV_OR9_cROT_2hROTnoOGD_F24h_DAPI_CD11b_Blank_MT_Slice_A_40xmd_2.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/051925_P10F_4DIV_OR9_cROT_2hROTnoOGD_F24h_DAPI_CD11b_Blank_MT_Slice_A_40xmd_3.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/051925_P10F_4DIV_OR9_cROT_2hROTnoOGD_F24h_DAPI_CD11b_Blank_MT_Slice_A_40xmd_4.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/051925_P10F_4DIV_OR9_cROT_2hROTnoOGD_F24h_DAPI_CD11b_Blank_MT_Slice_A_40xmd_5.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/060225_P10F_4DIV_OR10_OR10_cROT_2ROTonly_F24h_CD11b_MT_DAPI_Slice_D_40x_ctx_1.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/060225_P10F_4DIV_OR10_OR10_cROT_2ROTonly_F24h_CD11b_MT_DAPI_Slice_D_40x_ctx_2.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/060225_P10F_4DIV_OR10_OR10_cROT_2ROTonly_F24h_CD11b_MT_DAPI_Slice_D_40x_ctx_3.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/060225_P10F_4DIV_OR10_OR10_cROT_2ROTonly_F24h_CD11b_MT_DAPI_Slice_D_40x_ctx_4.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/060225_P10F_4DIV_OR10_OR10_cROT_2ROTonly_F24h_CD11b_MT_DAPI_Slice_D_40x_ctx_5.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/060225_P10F_4DIV_OR10_OR10_cROT_2ROTonly_F24h_CD11b_MT_DAPI_Slice_D_40x_ctx_6.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/060225_P10F_4DIV_OR10_OR10_cROT_2ROTonly_F24h_CD11b_MT_DAPI_Slice_D_40x_ctx_7.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/060225_P10F_4DIV_OR10_OR10_cROT_2ROTonly_F24h_CD11b_MT_DAPI_Slice_D_40x_mb_1.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/060225_P10F_4DIV_OR10_OR10_cROT_2ROTonly_F24h_CD11b_MT_DAPI_Slice_D_40x_mb_2.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/060225_P10F_4DIV_OR10_OR10_cROT_2ROTonly_F24h_CD11b_MT_DAPI_Slice_D_40x_mb_3.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/060225_P10F_4DIV_OR10_OR10_cROT_2ROTonly_F24h_CD11b_MT_DAPI_Slice_D_40x_mb_4.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/060225_P10F_4DIV_OR10_OR10_cROT_2ROTonly_F24h_CD11b_MT_DAPI_Slice_D_40x_mb_5.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/060225_P10F_4DIV_OR10_OR10_cROT_2ROTonly_F24h_CD11b_MT_DAPI_Slice_D_40x_mb_6.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/060225_P10F_4DIV_OR10_OR10_cROT_2ROTonly_F24h_CD11b_MT_DAPI_Slice_D_40x_mb_7.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/060225_P10F_4DIV_OR10_OR10_cROT_2ROTonly_F24h_CD11b_MT_DAPI_Slice_E_40x_ctx_1.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/060225_P10F_4DIV_OR10_OR10_cROT_2ROTonly_F24h_CD11b_MT_DAPI_Slice_E_40x_ctx_2.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/060225_P10F_4DIV_OR10_OR10_cROT_2ROTonly_F24h_CD11b_MT_DAPI_Slice_E_40x_ctx_3.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/060225_P10F_4DIV_OR10_OR10_cROT_2ROTonly_F24h_CD11b_MT_DAPI_Slice_E_40x_ctx_4.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/060225_P10F_4DIV_OR10_OR10_cROT_2ROTonly_F24h_CD11b_MT_DAPI_Slice_E_40x_ctx_5.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/060225_P10F_4DIV_OR10_OR10_cROT_2ROTonly_F24h_CD11b_MT_DAPI_Slice_E_40x_ctx_6.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/060225_P10F_4DIV_OR10_OR10_cROT_2ROTonly_F24h_CD11b_MT_DAPI_Slice_E_40x_ctx_7.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/060225_P10F_4DIV_OR10_OR10_cROT_2ROTonly_F24h_CD11b_MT_DAPI_Slice_E_40x_mb_1.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/060225_P10F_4DIV_OR10_OR10_cROT_2ROTonly_F24h_CD11b_MT_DAPI_Slice_E_40x_mb_2.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/060225_P10F_4DIV_OR10_OR10_cROT_2ROTonly_F24h_CD11b_MT_DAPI_Slice_E_40x_mb_3.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/060225_P10F_4DIV_OR10_OR10_cROT_2ROTonly_F24h_CD11b_MT_DAPI_Slice_E_40x_mb_4.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/060225_P10F_4DIV_OR10_OR10_cROT_2ROTonly_F24h_CD11b_MT_DAPI_Slice_F_40x_ctx_1.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/060225_P10F_4DIV_OR10_OR10_cROT_2ROTonly_F24h_CD11b_MT_DAPI_Slice_F_40x_ctx_2.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/060225_P10F_4DIV_OR10_OR10_cROT_2ROTonly_F24h_CD11b_MT_DAPI_Slice_F_40x_ctx_3.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/060225_P10F_4DIV_OR10_OR10_cROT_2ROTonly_F24h_CD11b_MT_DAPI_Slice_F_40x_ctx_4.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/060225_P10F_4DIV_OR10_OR10_cROT_2ROTonly_F24h_CD11b_MT_DAPI_Slice_F_40x_ctx_5.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/060225_P10F_4DIV_OR10_OR10_cROT_2ROTonly_F24h_CD11b_MT_DAPI_Slice_F_40x_ctx_6.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/060225_P10F_4DIV_OR10_OR10_cROT_2ROTonly_F24h_CD11b_MT_DAPI_Slice_F_40x_mb_1.tif', '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/2R_control/cd11b/060225_P10F_4DIV_OR10_OR10_cROT_2ROTonly_F24h_CD11b_MT_DAPI_Slice_F_40x_mb_2.tif']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(tif_file_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "046458cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.draw import disk\n",
    "\n",
    "def create_mask_from_centroids(df, image_shape):\n",
    "    mask = np.zeros(image_shape, dtype=np.uint8)\n",
    "\n",
    "    \n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        center = ((row['i']*2), (row['j']*2))  # (row, col) = (y, x)\n",
    "        radius = (row['ideal_radius']*2)\n",
    "\n",
    "        rr, cc = disk(center, radius, shape=image_shape)\n",
    "        mask[rr, cc] = 1\n",
    "\n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "1a576ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1,3, figsize=(15,5))\n",
    "# ax[0].imshow(first_mask[1])\n",
    "# ax[1].imshow(images[first_tif_idx][0,:,:])\n",
    "\n",
    "# test_file = all_prop[all_prop[\"file_name\"] == \"060225_P10F_4DIV_OR10_G11_ORST_F24h_CD11B_MT_DAPI_Slice_F_40x_ctx_7\"]\n",
    "# #ax[2].scatter(test_file[\"j\"], -test_file[\"i\"])\n",
    "\n",
    "# ax[2].imshow(create_mask_from_centroids(test_file, (1024, 1024)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "565e5d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(len(npy_masks[0:20]), 2, figsize=(16,80))\n",
    "\n",
    "# for ax, matt_im, nels_im in zip(axes, tif_file_paths, matt_masks):\n",
    "\n",
    "#     mask_overlay = create_overlay(matt_im[1], (create_nuclei_mask((nels_im[0]))))\n",
    "#     mask_overlay_alt = create_overlay(matt_im[1], (nels_im[0]))\n",
    "\n",
    "#     ax[0].imshow(mask_overlay)\n",
    "#     ax[1].imshow((mask_overlay_alt))\n",
    "\n",
    "\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "b7b82e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#min_vals, max_vals = compute_batch_channel_stats(tif_file_paths, channels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "1d150856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized_images = []\n",
    "\n",
    "# for image in tif_file_paths:\n",
    "#     norm_im = load_and_normalise_image(image, min_vals, max_vals)\n",
    "#     normalized_images.append(norm_im[:,:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "9452838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(images[14][2,:,:].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "f77ffec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create subplots\n",
    "# n = len(tif_files)\n",
    "# fig, axes = plt.subplots(n, 2, figsize=(10,n*4))  \n",
    "\n",
    "# # If there's only one image, axes won't be iterable\n",
    "# if n == 1:\n",
    "#     axes = [axes]\n",
    "\n",
    "# for ax, img, path in zip(axes, images, images):\n",
    "\n",
    "#     perc = np.percentile(img[1,:,:], 99)\n",
    "#     ax[0].imshow(remove_small_objects(img[2,:,:]>perc, min_size=10), cmap=\"gray\")\n",
    "#     ax[1].imshow(path[2,:,:,], cmap=\"gray\") #why?\n",
    "#     #ax.set_title(path)\n",
    "#     #ax.axis(\"off\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d176ba1",
   "metadata": {},
   "source": [
    "### Microglia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "cf9e1a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# thresh_li = filters.threshold_li(images[0][1,:,:])\n",
    "# binary_li = images[0][1,:,:] > thresh_li\n",
    "\n",
    "# #Remove small objects and fill holes\n",
    "# binary_li = remove_small_objects(\n",
    "#     binary_li, min_size=70\n",
    "#     )\n",
    "# binary_li = ndimage.binary_fill_holes(binary_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "d5a76c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create subplots\n",
    "# n = len(images)\n",
    "# fig, axes = plt.subplots(n, 1, figsize=(20,60))  \n",
    "\n",
    "# # If there's only one image, axes won't be iterable\n",
    "# if n == 1:\n",
    "#     axes = [axes]\n",
    "\n",
    "# for ax, img, path in zip(axes, images, images):\n",
    "\n",
    "#     img = img[1,:,:]\n",
    "\n",
    "\n",
    "#     #img = ((img- img.min()) * (1/(img.max() - img.min()) * 255)).astype('uint8')\n",
    "#     # super_threshold_indices = img < 5\n",
    "#     # img[super_threshold_indices] = 0\n",
    "\n",
    "#     thresh_li = filters.threshold_li(img)\n",
    "#     binary_li = img > thresh_li\n",
    "\n",
    "#     thresh_isodata = filters.threshold_isodata(img)\n",
    "#     binary_isodata = img > thresh_isodata  \n",
    "\n",
    "#     thresh_otsu = filters.threshold_otsu(img)\n",
    "#     binary_otsu = img > thresh_otsu\n",
    "\n",
    "#     thresh_triangle = filters.threshold_triangle(img)\n",
    "#     binary_triangle = img > thresh_triangle\n",
    "\n",
    "#     max_num_pixels = 800 / ((0.4315837)*(0.4318837))\n",
    "\n",
    "#     objects = label(binary_li)\n",
    "#     large_objects = remove_small_objects(objects, min_size=8590)\n",
    "#     small_objects = label((objects ^ large_objects) > thresh_li)\n",
    "\n",
    "#     scaled_img = ((img- img.min()) * (1/(img.max() - img.min()) * 255)).astype('uint8')\n",
    "#     scaled_thresh_li = filters.threshold_li(scaled_img)\n",
    "#     scaled_binary_li = scaled_img > scaled_thresh_li\n",
    "\n",
    "#     hist = np.histogram(scaled_img.flatten(), range=[0,50], bins=50)\n",
    "\n",
    "#     #if hist[0][0] > (hist[0][1] + hist[0][2]):\n",
    "\n",
    "#     ax.imshow(remove_small_objects(img), cmap=\"gray\") #why?\n",
    "#     # ax[1].imshow(ndimage.binary_fill_holes(remove_small_objects(binary_li, min_size=71)), cmap=\"gray\")\n",
    "#     # ax[2].imshow(ndimage.binary_fill_holes(remove_small_objects(binary_isodata, min_size=71)), cmap=\"gray\")\n",
    "#     # ax[3].imshow(ndimage.binary_fill_holes(remove_small_objects(binary_otsu, min_size=71)), cmap=\"gray\")\n",
    "#     # ax[4].imshow(ndimage.binary_fill_holes(remove_small_objects(binary_triangle, min_size=71)), cmap=\"gray\")\n",
    "#     #ax[2].imshow(ndimage.binary_fill_holes(remove_small_objects(small_objects > thresh_li, min_size=71)), cmap=\"gray\")\n",
    "#     #ax[3].hist((scaled_img).flatten(), range=[0,50], bins=50)\n",
    "\n",
    "#     #else:\n",
    "#         #print(f'{hist[0][0]}, {(hist[0][1] + hist[0][2])}')\n",
    "\n",
    "    \n",
    "#     #ax.set_title(path)\n",
    "#     #ax.axis(\"off\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "3a907691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist = np.histogram(scaled_img.flatten(), range=[0,50], bins=50)\n",
    "# hist[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "ca8e8397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create subplots\n",
    "# n = len(images)\n",
    "# fig, axes = plt.subplots(n, 2, figsize=(20, 50))  \n",
    "\n",
    "# # If there's only one image, axes won't be iterable\n",
    "# if n == 1:\n",
    "#     axes = [axes]\n",
    "\n",
    "# for ax, img, path in zip(axes, images, images):\n",
    "\n",
    "#     img = img[1,:,:]\n",
    "\n",
    "\n",
    "#     scaled_img = ((img- img.min()) * (1/(img.max() - img.min()) * 255)).astype('uint8')\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#     ax[0].imshow((scaled_img), cmap=\"gray\") \n",
    "#     ax[1].hist((scaled_img).flatten(), range=[0,50], bins=50)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5186bf",
   "metadata": {},
   "source": [
    "### Overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "ed97cae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_microglia_mask(image, threshold_methold=filters.threshold_li):\n",
    "\n",
    "    thresh_li = filters.threshold_li(image)\n",
    "    binary_li = image > thresh_li\n",
    "\n",
    "    objects = label(binary_li)\n",
    "    objects = clear_border(objects)\n",
    "    large_objects = remove_small_objects(objects, min_size=8590)\n",
    "    small_objects = label((objects ^ large_objects) > thresh_li)\n",
    "\n",
    "    binary_li = ndimage.binary_fill_holes(remove_small_objects(small_objects > thresh_li, min_size=71))\n",
    "\n",
    "    scaled_img = ((image - image.min()) * (1/(image.max() - image.min()) * 255)).astype('uint8')\n",
    "    hist = np.histogram(scaled_img.flatten(), range=[0,50], bins=50)\n",
    "\n",
    "    # if hist[0][0] > (hist[0][1] + hist[0][2]):\n",
    "\n",
    "    #     # Save the binary mask as .npy\n",
    "    #     #np.save(output_path, binary_li)\n",
    "    #     #print(f\"Processed: {input_path} -> {output_path}\")\n",
    "\n",
    "    # else:\n",
    "    #     print(\"Too much background, not using image\")\n",
    "\n",
    "    return binary_li\n",
    "\n",
    "def create_mitochondria_mask(image, percentile=99, min_size=10):\n",
    "\n",
    "    perc = np.percentile(image, percentile)\n",
    "    mito_mask = remove_small_objects(image>perc, min_size=min_size)\n",
    "    return mito_mask\n",
    "\n",
    "def create_nuclei_mask(image):\n",
    "    \n",
    "    thresh_li = filters.threshold_li(image)\n",
    "    binary_li = image > thresh_li\n",
    "    nuclei_mask = remove_small_objects(binary_li)\n",
    "    nuclei_mask = ndimage.binary_fill_holes(nuclei_mask)\n",
    "    return nuclei_mask\n",
    "\n",
    "def create_matt_mask(image):\n",
    "    thresh_li = filters.threshold_li(image)\n",
    "    binary_li = image > thresh_li\n",
    "    nuclei_mask = remove_small_objects(image)\n",
    "    nuclei_mask = ndimage.binary_fill_holes(nuclei_mask)\n",
    "    return nuclei_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "2ee3622d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "40\n",
      "40\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "mito_masks = []\n",
    "microg_masks = []\n",
    "pyknotic_nuclei_masks = []\n",
    "non_pyknotic_nuclei_masks = []\n",
    "\n",
    "#fig, axes = plt.subplots(len(tif_file_paths), 1, figsize=(10,5*len(tif_file_paths)))\n",
    "\n",
    "for file_name in microglia_mask_filepaths:\n",
    "\n",
    "    #file_idx = tif_file_paths.index(file_name)\n",
    "\n",
    "    microglia_im = np.load(file_name)\n",
    "    tif_name = file_name.split(\"/\")[-1].replace(\"_li_thresh.npy\", \".tif\")\n",
    "\n",
    "    image = tiff.imread(str(directory)+\"/\"+tif_name)\n",
    "\n",
    "\n",
    "    file_name = (tif_name.split(\"/\")[-1].split(\".\")[0])\n",
    "\n",
    "\n",
    "    scaled_img = ((image[1,:,:] - image[1,:,:].min()) * (1/(image[1,:,:].max() - image[1,:,:].min()) * 255)).astype('uint8')\n",
    "    hist = np.histogram(scaled_img.flatten(), range=[0,50], bins=50)\n",
    "    #ax.hist(scaled_img.flatten(), range=[0,50], bins=50)\n",
    "\n",
    "    mito_masks.append(create_mitochondria_mask(image[2,:,:]))\n",
    "    microg_masks.append(create_microglia_mask(image[1,:,:]))\n",
    "\n",
    "    pyknotic_mask = pyknotic_df[pyknotic_df[\"file_name\"] == file_name]\n",
    "    non_pyknotic_mask = non_pyknotic_df[non_pyknotic_df[\"file_name\"] == file_name]\n",
    "\n",
    "    pyknotic_nuclei_mask = create_mask_from_centroids(pyknotic_mask, (1024,1024))\n",
    "    non_pyknotic_nuclei_mask = create_mask_from_centroids(non_pyknotic_mask, (1024, 1024))\n",
    "    pyknotic_nuclei_masks.append(pyknotic_nuclei_mask)\n",
    "    non_pyknotic_nuclei_masks.append(non_pyknotic_nuclei_mask)\n",
    "\n",
    "print(len(microg_masks))\n",
    "print(len(mito_masks))\n",
    "print(len(pyknotic_nuclei_masks))\n",
    "print(len(non_pyknotic_nuclei_masks))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "94d79bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grayscale_background = np.mean(images[0][:3, :, :], axis=2)\n",
    "#overlay = np.stack([grayscale_background]*3, axis=-1).astype(np.uint8)\n",
    "\n",
    "\n",
    "def create_overlay(mito_mask, nuclei_mask):\n",
    "    # Initialize overlay image\n",
    "    overlay = np.zeros([mito_mask.shape[0], mito_mask.shape[1], 3], dtype=np.uint8)\n",
    "\n",
    "    # Define colors\n",
    "    nuclei_color = [0, 0, 255]        # Blue\n",
    "    microglia_color = [0, 255, 0]     # green\n",
    "    mito_color = [255, 0, 255]        # Magenta\n",
    "\n",
    "    # Create composite masks\n",
    "    #nuclei_within_microglia = np.logical_and(nuclei_mask, microglia_mask)\n",
    "\n",
    "    # Assign colors\n",
    "    #overlay[microglia_mask > 0] = microglia_color\n",
    "    overlay[mito_mask > 0] = mito_color\n",
    "    #overlay[nuclei_within_microglia > 0] = nuclei_color\n",
    "    overlay[nuclei_mask > 0] = nuclei_color\n",
    "\n",
    "    return overlay, nuclei_mask#, nuclei_within_microglia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "49705a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create subplots\n",
    "subset_pyk_masks = []\n",
    "subset_non_pyk_masks = []\n",
    "n = len(pyknotic_nuclei_masks)\n",
    "#fig, axes = plt.subplots(n, 2, figsize=(10,n*4))\n",
    "\n",
    "for pyknotic, non_pyknotic, mito_mask in zip(pyknotic_nuclei_masks, non_pyknotic_nuclei_masks, mito_masks):\n",
    "\n",
    "    #ax[1].scatter(all_prop_data[\"j\"]*2, -all_prop_data[\"i\"]*2)\n",
    "    #ax[1].imshow(nuclei_masks[file_idx])\n",
    "\n",
    "    pyk_overlay, pyk_mask = create_overlay(mito_mask, pyknotic)\n",
    "    non_pyk_overlay, non_pyk_mask = create_overlay(mito_mask, non_pyknotic)\n",
    "    #ax[0].imshow(pyk_overlay)\n",
    "    #ax[1].imshow(non_pyk_overlay)\n",
    "    subset_pyk_masks.append(pyk_mask)\n",
    "    subset_non_pyk_masks.append(non_pyk_mask)\n",
    "    # image_name = str(tif_file_paths[i]).split(\"/\")[-1]\n",
    "    # key_end = image_name.split(\"_\")\n",
    "    # title = f'{key_end[-5]}_{key_end[-4]}_{key_end[-3]}_{key_end[-2]}_{key_end[-1]}'\n",
    "    # axes[i].title.set_text(title)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "87e241b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_dictionary(file_name, X_props, Y_props, max_distance, nuclei_count=0):\n",
    "\n",
    "    \n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # Precompute all nuclei centroids\n",
    "    nuclei_centroids = np.array([obj.centroid for obj in X_props])\n",
    "    nuclei_labels = [obj.label for obj in X_props]\n",
    "    nuclei_radii = np.sqrt(np.array([obj.area for obj in X_props]) / np.pi)\n",
    "\n",
    "\n",
    "    distance_dict = {}\n",
    "\n",
    "    # Build KDTree once\n",
    "    tree = cKDTree(nuclei_centroids)\n",
    "\n",
    "    \n",
    "    # For each mito centroid, query the closest nucleus\n",
    "    for mito_object in Y_props:\n",
    "        mito_centroid = np.array(mito_object.centroid)\n",
    "        mito_radius = np.sqrt(mito_object.area)/np.pi\n",
    "        \n",
    "        dist, idx = tree.query(mito_centroid)\n",
    "        closest_label = nuclei_labels[idx]\n",
    "        closest_centroid = nuclei_centroids[idx]\n",
    "        closest_radii = nuclei_radii[idx]\n",
    "        \n",
    "\n",
    "        if dist < max_distance or dist == max_distance:\n",
    "\n",
    "            if closest_label in distance_dict.keys():\n",
    "                distance_dict[closest_label].append([closest_label, dist, closest_centroid, mito_centroid])\n",
    "            else: \n",
    "                distance_dict[closest_label] = [closest_label, dist, closest_centroid, mito_centroid]\n",
    "\n",
    "    \n",
    "\n",
    "            new_row = pd.DataFrame(\n",
    "                    {'filename': [file_name.split(\"/\")[-1]],\n",
    "                    'nuclei': [closest_label + nuclei_count],\n",
    "                    'centroid_distance': [dist], \n",
    "                    'nuclei_ideal_radius': [closest_radii],\n",
    "                    'nuc_centroid_x': [closest_centroid[0]], \n",
    "                    'nuc_centroid_y': [closest_centroid[1]], \n",
    "                    'mito_ideal_radius': [mito_radius],\n",
    "                    'mito_centroid_x': [mito_centroid[0]],\n",
    "                    'mito_centroid_y': [mito_centroid[1]],\n",
    "                    'total_nuclei': [len(X_props)],}\n",
    "                    #'total_mito_objects': [len(Y_props)]}\n",
    "                )\n",
    "            \n",
    "            df = pd.concat([df, new_row], ignore_index=True)\n",
    "    df[\"total_mito_objects\"] = len(df)\n",
    "    return distance_dict, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "034b02a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no pyknotic cells\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances = []\n",
    "dfs = pd.DataFrame()\n",
    "nuclei_count = 0\n",
    "for i in range(len(subset_pyk_masks)):\n",
    "    X = label(subset_pyk_masks[i])\n",
    "    Y = label(mito_masks[i])\n",
    "    X_props = regionprops(X)\n",
    "    Y_props = regionprops(Y)\n",
    "\n",
    "    if len(X_props) > 0:\n",
    "\n",
    "        cur_distance_dict, cur_df = get_distance_dictionary(file_name=tif_file_paths[i], X_props=X_props, Y_props=Y_props, max_distance=37, nuclei_count=nuclei_count)\n",
    "        distances.append(cur_distance_dict)\n",
    "        dfs = pd.concat([dfs, cur_df], ignore_index=True)\n",
    "        nuclei_count = len(dfs)\n",
    "    else:\n",
    "        print('no pyknotic cells')\n",
    "        pass\n",
    "\n",
    "title = str(directory).split(\"/\")\n",
    "treatment_condition = f\"{title[-2]}_{title[-1]}\"\n",
    "dfs['treatment_condition'] = treatment_condition\n",
    "dfs.to_csv(f'/Users/nelsschimek/Documents/nancelab/saffron/distances_data/pyknotic_{title[-2]}_Nuclei_Mito_distances_{title[-1]}.csv')\n",
    "len(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "8aea7f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1552"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances = []\n",
    "dfs = pd.DataFrame()\n",
    "nuclei_count = 0\n",
    "for i in range(len(subset_non_pyk_masks)):\n",
    "    X = label(subset_non_pyk_masks[i])\n",
    "    Y = label(mito_masks[i])\n",
    "    X_props = regionprops(X)\n",
    "    Y_props = regionprops(Y)\n",
    "\n",
    "    cur_distance_dict, cur_df = get_distance_dictionary(file_name=tif_file_paths[i], X_props=X_props, Y_props=Y_props, max_distance=37, nuclei_count=nuclei_count)\n",
    "    distances.append(cur_distance_dict)\n",
    "    dfs = pd.concat([dfs, cur_df], ignore_index=True)\n",
    "    nuclei_count = len(dfs)\n",
    "\n",
    "title = str(directory).split(\"/\")\n",
    "treatment_condition = f\"{title[-2]}_{title[-1]}\"\n",
    "dfs['treatment_condition'] = treatment_condition\n",
    "dfs.to_csv(f'/Users/nelsschimek/Documents/nancelab/saffron/distances_data/non_pyknotic_{title[-2]}_Nuclei_Mito_distances_{title[-1]}.csv')\n",
    "len(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cff1936",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(subset_pyk_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e50fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a0309a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_distances(distance_dict_list):\n",
    "\n",
    "#     plt.figure(figsize=(4, 4))\n",
    "\n",
    "#     for key, value in distance_dict.items():\n",
    "#         # Process the primary vector\n",
    "#         if isinstance(value[2], np.ndarray) and isinstance(value[3], np.ndarray):\n",
    "#             start = value[2]\n",
    "#             end = value[3]\n",
    "#             dx = end[0] - start[0]\n",
    "#             dy = end[1] - start[1]\n",
    "#             plt.arrow(start[0], start[1], dx, dy, head_width=3, head_length=3, fc='blue', ec='blue')\n",
    "#             plt.plot(start[0], start[1], 'g.')  # Start point\n",
    "#             plt.plot(end[0], end[1], 'r.')      # End point\n",
    "#             #plt.text(start[0], start[1], str(key), fontsize=8, color='black')\n",
    "\n",
    "#         # Process sub-vectors (if any)\n",
    "#         for sub in value[4:]:\n",
    "#             if isinstance(sub, list) and len(sub) >= 4:\n",
    "#                 sub_start = sub[2]\n",
    "#                 sub_end = sub[3]\n",
    "#                 dx = sub_end[0] - sub_start[0]\n",
    "#                 dy = sub_end[1] - sub_start[1]\n",
    "#                 plt.arrow(sub_start[0], sub_start[1], dx, dy, head_width=3, head_length=3, fc='gray', ec='gray')\n",
    "#                 plt.plot(sub_end[0], sub_end[1], 'r.')  # Smaller marker for sub-end\n",
    "\n",
    "#     #plt.gca().invert_xaxis()  # Optional for image-style coordinates\n",
    "#     #plt.gca().invert_yaxis()  # Optional for image-style coordinates\n",
    "#     plt.axis('equal')\n",
    "#     plt.xlabel('X')\n",
    "#     plt.ylabel('Y')\n",
    "#     plt.title('All Centroid Vectors (Primary and Sublists)')\n",
    "#     #plt.grid(True)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062a320d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_distance_plot(distance_dicts, max_distance=20, title=None):\n",
    "    \n",
    "\n",
    "    circle_one = Circle((max_distance, max_distance), 3, facecolor='none',\n",
    "                        edgecolor=(0, 0.8, 0.8), linewidth=3, alpha=0.5)\n",
    "    circle_two = Circle((max_distance, max_distance), max_distance, facecolor='none',\n",
    "                    edgecolor=(0, 0.2, 0.2), linewidth=3, alpha=0.5)\n",
    "    fig, ax = plt.subplots(figsize=(4,4))\n",
    "    ax.add_patch(circle_one)\n",
    "    ax.add_patch(circle_two)\n",
    "    \n",
    "    for distance_dict in distance_dicts:\n",
    "\n",
    "        \n",
    "\n",
    "        for key, value in distance_dict.items():\n",
    "            # Process the primary vector\n",
    "            if isinstance(value[2], np.ndarray) and isinstance(value[3], np.ndarray):\n",
    "                start = value[2]\n",
    "                end = value[3]\n",
    "                dx = end[0] - start[0]\n",
    "                dy = end[1] - start[1]\n",
    "                ax.arrow(max_distance, max_distance, dx, dy, head_width=0.1, head_length=0.1, fc='blue', ec='blue', alpha=0.1)\n",
    "                #ax.plot(start[0], start[1], 'g.')  # Start point\n",
    "                #ax.plot(end[0], end[1], 'r.')      # End point\n",
    "                #ax.text(start[0], start[1], str(key), fontsize=8, color='black')\n",
    "\n",
    "            # Process sub-vectors (if any)\n",
    "            for sub in value[4:]:\n",
    "                if isinstance(sub, list) and len(sub) >= 4:\n",
    "                    sub_start = sub[2]\n",
    "                    sub_end = sub[3]\n",
    "                    dx = sub_end[0] - sub_start[0]\n",
    "                    dy = sub_end[1] - sub_start[1]\n",
    "                    ax.arrow(max_distance, max_distance, dx, dy, head_width=0.1, head_length=0.1, fc='blue', ec='blue', alpha=0.1)\n",
    "                    #ax.plot(sub_end[0], sub_end[1], 'r.')  # Smaller marker for sub-end\n",
    "\n",
    "    ax.set_xlim([0,(max_distance*2)])\n",
    "    ax.set_ylim([0,(max_distance*2)])\n",
    "    ax.set_title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62cd17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = str(directory).split(\"/\")\n",
    "make_distance_plot(distance_dicts=distances, title=f'{title[-2]} Nuclei Mito distances {title[-1]} (16uM)', max_distance=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ce57e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae0dc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_file = '/Users/nelsschimek/Documents/nancelab/Data/mito_images/brendan_full_analysis/tifs/HC/cd11b/li_thresh/060225_P10F_4DIV_OR10_control_HC_F24h_DAPI_CD11b_Blank_MT_Slice_A_40x_mb_3_li_thresh.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5378c84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "from skimage.segmentation import clear_border\n",
    "\n",
    "binary_mask = np.load(mask_file)\n",
    "\n",
    "# Label connected regions in the binary mask\n",
    "label_image = label(binary_mask)\n",
    "cleaned_mask = clear_border(labels=label_image)\n",
    "\n",
    "# Measure properties\n",
    "props = skimage.measure.regionprops_table((label_image))\n",
    "\n",
    "# Create a DataFrame for the current file\n",
    "props_df = pd.DataFrame(props)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1e20a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cleaned_mask, cmap=\"gray\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vampire",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
